#!/usr/bin/env bash
#vim:syntax=bash

# NO, below we use the let command to evaluate expressions. When the result
# is zero and set -e is active this script exits.
# set -e

export PCROPTIONS=--nothing

gdalTranslate="@GDAL_TRANSLATE@ -quiet"
west=100000.0
south=199850.0
cellSize=50.0

# gdalrasterdrivertest
echo "NCOLS 2"                > values.col
echo "NROWS 3"               >> values.col
echo "XLLCORNER $west"       >> values.col
echo "YLLCORNER $south"      >> values.col
echo "CELLSIZE $cellSize"    >> values.col
echo "NODATA_VALUE 3.0"      >> values.col
echo 3.0 3.0                 >> values.col
echo 3.0 3.0                 >> values.col
echo 3.0 3.0                 >> values.col
$gdalTranslate -ot Byte -mo "PCRASTER_VALUESCALE=VS_BOOLEAN" -of PCRaster values.col allmv.pcrmap

# make --silent -f $DAL/sources/pcraster_dal/Makefile.testrun all
# cp $DAL/sources/pcraster_dal/Makefile.testrun .
make --silent -f Makefile.testrun all

# ------------------------------------------------------------------------------
# MatrixDriverTest
# Simple matrix with only numbers.
echo  1  2  3   >  matrix1.txt
echo  4 -5  6   >> matrix1.txt
echo  7  8  9   >> matrix1.txt
echo 10 11 12   >> matrix1.txt
echo 13 14 15.5 >> matrix1.txt
echo 16 17 18   >> matrix1.txt

# Weights matrix.
echo 1 1 1 >  matrix2.txt
echo 1 0 1 >> matrix2.txt
echo 1 1 1 >> matrix2.txt

# Matrix to be read as string values.
echo 1 1.0 1 >  matrix3.txt
echo 1 0   1 >> matrix3.txt
echo 1 1   a >> matrix3.txt

# Matrix which should give a parse error.
echo  1  2  3   >  matrix4.txt
echo  4 -5  6   >> matrix4.txt
echo  7  8  9   >> matrix4.txt
echo 10 11 12   >> matrix4.txt
echo 13 14 15.5 >> matrix4.txt
echo 16 17 a    >> matrix4.txt

# ------------------------------------------------------------------------------
# GeoEASTableDriverTest
echo  Special table >  table1.eas
echo  3             >> table1.eas
echo  One           >> table1.eas
echo  Two           >> table1.eas
echo  Three         >> table1.eas
echo  1  2  3       >> table1.eas
echo  4 -5  6       >> table1.eas
echo  7  8  9       >> table1.eas
echo 10 11 12       >> table1.eas
echo 13 14 15.5     >> table1.eas
echo 16 17 1e31     >> table1.eas

echo Attributes of the zones.           >  table2.eas
echo 12                                 >> table2.eas
echo Zone number                        >> table2.eas
echo Number of dwellings                >> table2.eas
echo Urbanity                           >> table2.eas
echo Less then 300 m3, 2 rooms          >> table2.eas
echo Less then 300 m3, 3 rooms          >> table2.eas
echo Less then 300 m3, 4 rooms          >> table2.eas
echo Between 300 and 600 m3, 3 rooms    >> table2.eas
echo Between 300 and 600 m3, 4 rooms    >> table2.eas
echo Between 300 and 600 m3, 5 rooms    >> table2.eas
echo Greater than 600 m3, 4 rooms       >> table2.eas
echo Greater than 600 m3, 5 rooms       >> table2.eas
echo Greater than 600 m3, 6 rooms       >> table2.eas
echo 1 266 2  7  7 10  8  8 10 15 15 20 >> table2.eas
echo 2 386 2 15 15 20  9  9 12  6  6  8 >> table2.eas
echo 3 372 2 21 21 28  6  6  8  3  3  4 >> table2.eas
echo 4 304 2  6  6  8 12 12 16 12 12 16 >> table2.eas
echo 5 651 5 20 15 15 12  9  9  8  6  6 >> table2.eas
echo 6 340 5  8  6  6 16 12 12 16 12 12 >> table2.eas
echo 7 136 8 20 12  8 18 11  6 13  8  4 >> table2.eas
echo 8  45 8 10  6  4 20 12  8 20 12  8 >> table2.eas

# ------------------------------------------------------------------------------
# # SQLTableDriverTest
# if [ $OSTYPE = "linux-gnu" ]
# then
#   if [ `which isql` ] # and $LOGNAME != kor ]
#   then
#     # Trouble shooting:
#     # - [ISQL]ERROR: Could not SQLConnect
#     #   ODBC doesn't know about the daltest DSN, see odbcinst command
#     # - [ISQL]ERROR: Could not SQLExecute
#     #   We delete the table here in case it is still lying around. If it is
#     #   already gone, this error message is printed, no worries.
# 
#     # Update $HOME/.odbc.ini so the daltest DSN is known by the ODBC driver.
#     odbcinst -i -s -f $DAL/Sources/PCRasterDal/odbctestdb.txt
# 
#     # Table might still be around when unit tests dumped/threw/...
#     # Delete it first.
# 
#     if [ -e daltest ]; then
#       cat $DAL/Sources/PCRasterDal/deleteExampleTable | isql daltest $LOGNAME -b | grep --invert "SQLRowCount returns"
#     fi
# 
#     # Create a fresh table.
#     cat $DAL/Sources/PCRasterDal/createExampleTable | isql daltest $LOGNAME -b | grep --invert "SQLRowCount returns"
#   fi
# fi

# ------------------------------------------------------------------------------

# StackInfoTest
# soil0000.010+100
for((i = 10; i <= 100; ++i))
do
  echo "NCOLS 2" > soil.col
  echo "NROWS 3" >> soil.col
  echo "XLLCORNER $west" >> soil.col
  echo "YLLCORNER $south" >> soil.col
  echo "CELLSIZE $cellSize" >> soil.col
  echo "NODATA_VALUE -1.0" >> soil.col
  echo $i 1    >> soil.col
  echo  2 -1.0 >> soil.col
  echo $i 3    >> soil.col
  $gdalTranslate -ot Int32 -mo "PCRASTER_VALUESCALE=VS_NOMINAL" -of PCRaster soil.col `printf "soil0000.%.3d" $i`
done

echo "NCOLS 2"                > values.col
echo "NROWS 3"               >> values.col
echo "XLLCORNER $west"       >> values.col
echo "YLLCORNER $south"      >> values.col
echo "CELLSIZE $cellSize"    >> values.col
echo "NODATA_VALUE -1.0"     >> values.col
echo  1.0  1.0               >> values.col
echo  1.0  1.0               >> values.col
echo  1.0  1.0               >> values.col
$gdalTranslate -ot Float32 -mo "PCRASTER_VALUESCALE=VS_SCALAR" -of PCRaster values.col "values00.010"

echo "NCOLS 2"                > values.col
echo "NROWS 3"               >> values.col
echo "XLLCORNER $west"       >> values.col
echo "YLLCORNER $south"      >> values.col
echo "CELLSIZE $cellSize"    >> values.col
echo "NODATA_VALUE -1.0"     >> values.col
echo  6.0  6.0               >> values.col
echo  6.0  6.0               >> values.col
echo  6.0  6.0               >> values.col
$gdalTranslate -ot Float32 -mo "PCRASTER_VALUESCALE=VS_SCALAR" -of PCRaster values.col "values00.015"

echo "NCOLS 2"                > values.col
echo "NROWS 3"               >> values.col
echo "XLLCORNER $west"       >> values.col
echo "YLLCORNER $south"      >> values.col
echo "CELLSIZE $cellSize"    >> values.col
echo "NODATA_VALUE -1.0"     >> values.col
echo  11.0  11.0             >> values.col
echo  11.0  11.0             >> values.col
echo  11.0  11.0             >> values.col
$gdalTranslate -ot Float32 -mo "PCRASTER_VALUESCALE=VS_SCALAR" -of PCRaster values.col "values00.020"

rm values.col

# RasterDataSourceTest
echo "NCOLS 2"                > values.col
echo "NROWS 3"               >> values.col
echo "XLLCORNER $west"       >> values.col
echo "YLLCORNER $south"      >> values.col
echo "CELLSIZE $cellSize"    >> values.col
echo "NODATA_VALUE -1.0"     >> values.col
echo  1  2                   >> values.col
echo  4 -1.0                 >> values.col
echo  7  8                   >> values.col
$gdalTranslate -ot Int32 -mo "PCRASTER_VALUESCALE=VS_NOMINAL" -of PCRaster values.col soil.map
$gdalTranslate -ot Int32 -mo "PCRASTER_VALUESCALE=VS_NOMINAL" -of PCRaster values.col sillyname
$gdalTranslate -ot Int32 -mo "PCRASTER_VALUESCALE=VS_ORDINAL" -of PCRaster values.col sillyname.map

# ------------------------------------------------------------------------------
# Complex test data set 1 for data space with dimensions:
# Scenarios: {aap, noot, mies}
# Time: [10, 20, 1]
# CumulativeProbabilities: [0.1, 0.9, 0.01]
# Space: 3
# Space: 2

# ------------------------------------------------------------------------------
# quantile
# aap
# q\t  | 10   | 15   | 20
# -------------------------
# 0.1  |  0.0 |  1.0 |  2.0
# 0.25 |  4.0 |  5.0 |  6.0
# 0.5  |  5.0 |  6.0 |  7.0
# 0.75 |  6.0 |  7.0 |  8.0
# 0.9  | 10.0 | 11.0 | 12.0

# noot
# q\t  | 10   | 15   | 20
# -------------------------
# 0.1  | 10.0 | 11.0 | 12.0
# 0.25 | 14.0 | 15.0 | 16.0
# 0.5  | 15.0 | 16.0 | 17.0
# 0.75 | 16.0 | 17.0 | 18.0
# 0.9  | 20.0 | 21.0 | 22.0

# mies
# q\t  | 10   | 15   | 20
# -------------------------
# 0.1  | 20.0 | 21.0 | 22.0
# 0.25 | 24.0 | 25.0 | 26.0
# 0.5  | 25.0 | 26.0 | 27.0
# 0.75 | 26.0 | 27.0 | 28.0
# 0.9  | 30.0 | 31.0 | 32.0
# ------------------------------------------------------------------------------

# Create directories.
mkdir -p dataset1
for scenario in aap noot mies
do
  mkdir -p dataset1/$scenario
done

function createRaster {
  value=$1
  outputFilename=$2

  echo "NCOLS 2"                > tmp.col
  echo "NROWS 3"               >> tmp.col
  echo "XLLCORNER $west"       >> tmp.col
  echo "YLLCORNER $south"      >> tmp.col
  echo "CELLSIZE $cellSize"    >> tmp.col
  echo "NODATA_VALUE -1.0"     >> tmp.col
  echo $value -1.0 >> tmp.col
  echo -1.0   -1.0 >> tmp.col
  echo -1.0   -1.0 >> tmp.col
  $gdalTranslate -ot Float32 -mo "PCRASTER_VALUESCALE=VS_SCALAR" -of PCRaster tmp.col $outputFilename
}

# Create rasters.
# scalar_x
for((t = 10; t <= 20; t += 1))
do
  # Upper left cell of scalar equals the time step.
  # All other cells are missing values for the time being.
  # 0: 10, 11, 12, 13, 14, 15
  if(($t != 15))
  then
    let v=t
    createRaster $v `printf "dataset1/aap/scalar_%d" $t`
  fi

  let v=t*2
  createRaster $v `printf "dataset1/noot/scalar_%d" $t`

  let v=t*3
  createRaster $v `printf "dataset1/mies/scalar_%d" $t`
done

# quantile_x_y
for((i = 0; i < 3; i++))
do
  let t=10+i*5

  let v=0+i*1
  createRaster $v `printf "dataset1/aap/quantile_%d_%g" $t 0.1`
  let v+=10
  createRaster $v `printf "dataset1/noot/quantile_%d_%g" $t 0.1`
  let v+=10
  createRaster $v `printf "dataset1/mies/quantile_%d_%g" $t 0.1`

  let v=4+i*1
  createRaster $v `printf "dataset1/aap/quantile_%d_%g" $t 0.25`
  let v+=10
  createRaster $v `printf "dataset1/noot/quantile_%d_%g" $t 0.25`
  let v+=10
  createRaster $v `printf "dataset1/mies/quantile_%d_%g" $t 0.25`

  let v=5+i*1
  createRaster $v `printf "dataset1/aap/quantile_%d_%g" $t 0.5`
  let v+=10
  createRaster $v `printf "dataset1/noot/quantile_%d_%g" $t 0.5`
  let v+=10
  createRaster $v `printf "dataset1/mies/quantile_%d_%g" $t 0.5`

  let v=6+i*1
  createRaster $v `printf "dataset1/aap/quantile_%d_%g" $t 0.75`
  let v+=10
  createRaster $v `printf "dataset1/noot/quantile_%d_%g" $t 0.75`
  let v+=10
  createRaster $v `printf "dataset1/mies/quantile_%d_%g" $t 0.75`

  let v=10+i*1
  createRaster $v `printf "dataset1/aap/quantile_%d_%g" $t 0.9`
  let v+=10
  createRaster $v `printf "dataset1/noot/quantile_%d_%g" $t 0.9`
  let v+=10
  createRaster $v `printf "dataset1/mies/quantile_%d_%g" $t 0.9`
done

# ------------------------------------------------------------------------------
# GDALRasterDriverTest

$gdalTranslate -of GTiff boolean.Result.map    boolean.tiff
$gdalTranslate -of GTiff areaarea.Class.imap   nominal.tiff
$gdalTranslate -of GTiff map2col.PCRmap2.imap  ordinal.tiff
$gdalTranslate -of GTiff abs.Expr.imap         scalar.tiff
$gdalTranslate -of GTiff nodirection.Expr.imap directional.tiff
$gdalTranslate -of GTiff accu.Ldd.imap         ldd.tiff
$gdalTranslate -of GTiff allmv.pcrmap          allmv.tiff

# soil0000.0xy -> soil_xy.pcrmap
# soil0000.0xy -> soil_xy.tiff
for((i = 10; i <= 100; ++i))
do
  # cp `printf "soil0000.%.3d soil_%.3d.pcrmap" $i`

  # # Remove the hdf4 first, because otherwise we get a lot of messages like:
  # # ERROR 6: Unable to determine files associated with soil_10.hdf4,
  # # delete fails.
  # rm -f `printf "soil_%d.hdf4" $i`

  # $gdalTranslate -of HDF4Image `printf "soil0000.%.3d soil_%d.hdf4" $i $i`
  $gdalTranslate -of GTiff `printf "soil0000.%.3d soil_%d.tiff" $i $i`
done

echo "ncols 3"         >  esriasciigrid1.asc
echo "nrows 4"         >> esriasciigrid1.asc
echo "xllcorner 3.0"   >> esriasciigrid1.asc
echo "yllcorner 4.0"   >> esriasciigrid1.asc
echo "cellsize 10.0"   >> esriasciigrid1.asc
echo "nodata_value -9999" >> esriasciigrid1.asc
echo "1 2 3"           >> esriasciigrid1.asc
echo "4 -9999 6"       >> esriasciigrid1.asc
echo "7 8 9"           >> esriasciigrid1.asc
echo "10 11 12"        >> esriasciigrid1.asc


# ------------------------------------------------------------------------------
# OgrFeatureDriverTest

# Data source definition.
echo "<OGRVRTDataSource>" > polygons.vrt
echo "  <OGRVRTLayer name=\"polygons\">" >> polygons.vrt
echo "    <SrcDataSource>polygons.csv</SrcDataSource>" >> polygons.vrt
echo "    <GeometryType>wkbPolygon</GeometryType>" >> polygons.vrt
echo "    <LayerSRS>WGS84</LayerSRS>" >> polygons.vrt
echo "    <GeometryField encoding=\"WKT\" field=\"wkt\"/>" >> polygons.vrt
echo "  </OGRVRTLayer>" >> polygons.vrt
echo "</OGRVRTDataSource>" >> polygons.vrt

# Attribute values. Internal table.
echo "id, wkt, attribute1, attribute2" > polygons.csv
echo "1, \"POLYGON((2 2, 4 2, 3 4, 2 2))\", 1.1, 1.2" >> polygons.csv
echo "2, \"POLYGON((4 6, 8 6, 8 8, 4 8, 4 6))\", 2.1, 2.2" >> polygons.csv

# Attribute types.
# No space between the types!
echo "\"Integer\",\"String\",\"Real\",\"Real\"" > polygons.csvt

# External table for
# - temporal attribute (1, 2)
# - uncertain attribute (0.01, 0.1, 0.5, 0.9, 0.99)
# - uncertain temporal attribute (
#   1_0.01, 1_0.1, 1_0.5, 1_0.9, 1_0.99
#   2_0.01, 2_0.1, 2_0.5, 2_0.9, 2_0.99)
# TODO This all works for sqlite tables stored in databases stored in files.
#      How about databases managed by other DBMS's?
# Note the reordering of the records. This will make sure that the join on
# fid works.
rm -f polygons.sql3
@SQLITE3_EXECUTABLE@ polygons.sql3 <<EOF
  create table polygons(
    'fid' INTEGER,
    'date' INTEGER,
    'attribute1' REAL,
    PRIMARY KEY ('fid', 'date'));
  insert into polygons values(2, 1, 12.1);
  insert into polygons values(1, 1, 11.1);
  insert into polygons values(2, 2, 12.2);
  insert into polygons values(1, 2, 11.2);
EOF

  #
  #   "Feature id" INTEGER primary key,

  #   "1" REAL, "2" REAL,
  #   "0.01" REAL, "0.1" REAL, "0.5" REAL, "0.9" REAL, "0.99" REAL,
  #   "1_0.01" REAL, "1_0.1" REAL, "1_0.5" REAL, "1_0.9" REAL, "1_0.99" REAL,
  #   "2_0.01" REAL, "2_0.1" REAL, "2_0.5" REAL, "2_0.9" REAL, "2_0.99" REAL);
  # insert into attribute1 values(
  #   1,
  #   11.1, 11.2,
  #   3.3, 4.4, 10.3, 17.5, 20.2,
  #   13.3, 14.4, 110.3, 117.5, 120.2,
  #   23.3, 24.4, 210.3, 217.5, 220.2);
  # insert into attribute1 values(
  #   2,
  #   12.1, 12.2,
  #   3.1, 4.2, 11.3, 16.6, 21.1,
  #   13.1, 14.2, 111.3, 116.6, 121.1,
  #   23.1, 24.2, 211.3, 216.6, 221.1);

# Uncertain attribute:
# feature quantile value
# 1       0.01     3.3
# 1       0.1      4.4
# 1       0.5      10.3
# 1       0.9      17.5
# 1       0.99     20.2
#
# 2       0.01     3.1
# 2       0.1      4.2
# 2       0.5      11.3
# 2       0.9      16.6
# 2       0.99     21.1
#
# - Test attribute values for available quantile levels
# - Test attribute values for unavailable quantile levels
# - Test exceedence chances for available values
# - Test exceedence chances for unavailable values
#
# Uncertain temporal attribute
# feature timestep quantile value
# 1       1        0.01     13.3
# 1       1        0.1      14.4
# 1       1        0.5      110.3
# 1       1        0.9      117.5
# 1       1        0.99     120.2
# 2       1        0.01     13.1
# 2       1        0.1      14.2
# 2       1        0.5      111.3
# 2       1        0.9      116.6
# 2       1        0.99     121.1
# 1       2        0.01     23.3
# 1       2        0.1      24.4
# 1       2        0.5      210.3
# 1       2        0.9      217.5
# 1       2        0.99     220.2
# 2       2        0.01     23.1
# 2       2        0.1      24.2
# 2       2        0.5      211.3
# 2       2        0.9      216.6
# 2       2        0.99     221.1
#
# - Test temporal attribute values for available quantile levels
# - Test temporal attribute values for unavailable quantile levels
# - Test exceedence chances for available temporal values
# - Test exceedence chances for unavailable temporal values

rm -f dimensions.sql3
@SQLITE3_EXECUTABLE@ dimensions.sql3 <<EOF
  create table date(
    'date' INTEGER,
    'co2' REAL,
    PRIMARY KEY ('date'));
  insert into date values(1, 1.11);
  insert into date values(2, 2.22);
  insert into date values(3, 3.33);
EOF

@SQLITE3_EXECUTABLE@ dimensions.sql3 <<EOF
  create table scenario(
    'scenario' STRING,
    'co2' REAL,
    PRIMARY KEY ('scenario'));
  insert into scenario values("aap" , -1.11);
  insert into scenario values("noot", -2.22);
EOF

@SQLITE3_EXECUTABLE@ dimensions.sql3 <<EOF
  create table scenario_date(
    'scenario' STRING,
    'date' INTEGER,
    'co2' REAL,
    PRIMARY KEY ('scenario', 'date'));
  insert into scenario_date values("aap" , 1, 1.01);
  insert into scenario_date values("aap" , 2, 2.01);
  insert into scenario_date values("noot", 1, 1.02);
  insert into scenario_date values("noot", 2, 2.02);
EOF

@SQLITE3_EXECUTABLE@ dimensions.sql3 <<EOF
  create table quantile(
    'quantile' REAL,
    'co2' REAL,
    PRIMARY KEY ('quantile'));
  insert into quantile values(0.01, 1.01);
  insert into quantile values(0.05, 1.05);
  insert into quantile values(0.50, 1.50);
  insert into quantile values(0.95, 1.95);
  insert into quantile values(0.99, 1.99);
EOF

@SQLITE3_EXECUTABLE@ dimensions.sql3 <<EOF
  create table scenario_date_quantile(
    'scenario' STRING,
    'date' INTEGER,
    'quantile' REAL,
    'co2' REAL,
    PRIMARY KEY ('scenario', 'date', 'quantile'));
  insert into scenario_date_quantile values("aap", 1, 0.01, 1.01);
  insert into scenario_date_quantile values("aap", 1, 0.05, 1.05);
  insert into scenario_date_quantile values("aap", 1, 0.50, 1.50);
  insert into scenario_date_quantile values("aap", 1, 0.95, 1.95);
  insert into scenario_date_quantile values("aap", 1, 0.99, 1.99);
  insert into scenario_date_quantile values("aap", 2, 0.01, 2.01);
  insert into scenario_date_quantile values("aap", 2, 0.05, 2.05);
  insert into scenario_date_quantile values("aap", 2, 0.50, 2.50);
  insert into scenario_date_quantile values("aap", 2, 0.95, 2.95);
  insert into scenario_date_quantile values("aap", 2, 0.99, 2.99);
  insert into scenario_date_quantile values("aap", 3, 0.01, 3.01);
  insert into scenario_date_quantile values("aap", 3, 0.05, 3.05);
  insert into scenario_date_quantile values("aap", 3, 0.50, 3.50);
  insert into scenario_date_quantile values("aap", 3, 0.95, 3.95);
  insert into scenario_date_quantile values("aap", 3, 0.99, 3.99);
EOF
